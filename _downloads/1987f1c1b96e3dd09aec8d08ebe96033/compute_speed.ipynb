{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n1D scattering transform benchmark\n=================================\nWe compute scattering transforms for signals of length `T = 2**16`, with scale\n`J = 10` and `Q = 8` wavelets per octave. The signals are stacked into batches\nof size `batch_size = 64` and the transform is computed `10` times to get an\naverage running time.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preliminaries\n-------------\nSince kymatio handles PyTorch arrays, we first import `torch`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To measure the running time of the implementation, we use the `time` package.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The performance of the implementation depends on which \"backend\" is used. We\ntherefore want to report the name of the backend when presenting the results.\nCertain backends are also GPU-only, we we want to detect that before running\nthe benchmark.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import kymatio.scattering1d.backend as backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we import the `Scattering1D` class that computes the scattering\ntransform.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from kymatio import Scattering1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmark setup\n--------------------\nFirst, we set up some basic parameters, the signal length `T`, the number of\nwavelets per octave `Q`, and the averaging scale, `2**J`. For a sampling rate\nof 11025 Hz, `T = 2**16` corresponds to about 6 seconds of audio, and an\naveraging scale of `2**10` is about 100 milliseconds, both of which are\ntypical values for these parameters in audio applications. For `Q`, 8\nwavelets per octave ensures that we are able to resolve isolated sinusoids\nwithout sacrificing too much temporal resolution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "T = 2**16\nJ = 10\nQ = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To squeeze the maximum performance out of the implementation, we apply it to\na batch of `64` signals. Larger batch sizes do not yield increased efficiency,\nbut smaller values increases the influence of overhead on the running time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We repeat the benchmark `10` times and compute the average running time to\nget a reasonable estimate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Determine which devices (CPU or GPU) that are supported by the current\nbackend.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "devices = []\nif backend.NAME == 'torch':\n    devices.append('cpu')\nif backend.NAME == 'torch' and torch.cuda.is_available():\n    devices.append('gpu')\nif backend.NAME == 'skcuda' and torch.cuda.is_available():\n    devices.append('gpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the `Scattering1D` object using the given parameters and generate\nsome compatible test data with the specified batch size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scattering = Scattering1D(J, T, Q)\n\nx = torch.randn(batch_size, T, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the benchmark\n-----------------\nFor each device, we need to convert the `scattering` object and the Tensor\n`x` to the appropriate type, invoke `times` calls to the `scattering.forward`\nand print the running times. Before the timer starts, we add an extra\n`scattering.forward` call to ensure any first-time overhead, such as memory\nallocation and CUDA kernel compilation, is not counted. If the benchmark is\nrunning on the GPU, we also need to call `torch.cuda.synchronize()` before\nand after the benchmark to make sure that all CUDA kernels have finished\nexecuting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for device in devices:\n    fmt_str = '==> Testing Float32 with {} backend, on {}, forward'\n    print(fmt_str.format(backend.NAME, device.upper()))\n\n    if device == 'gpu':\n        scattering.cuda()\n        x = x.cuda()\n    else:\n        scattering.cpu()\n        x = x.cpu()\n\n    scattering.forward(x)\n\n    if device == 'gpu':\n        torch.cuda.synchronize()\n\n    t_start = time.time()\n    for _ in range(times):\n        scattering.forward(x)\n\n    if device == 'gpu':\n        torch.cuda.synchronize()\n\n    t_elapsed = time.time() - t_start\n\n    fmt_str = 'Elapsed time: {:2f} [s / {:d} evals], avg: {:.2f} (s/batch)'\n    print(fmt_str.format(t_elapsed, times, t_elapsed/times))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The resulting output should be something like\n\n.. code-block:: text\n\n  ==> Testing Float32 with torch backend, on CPU, forward\n  Elapsed time: 27.158231 [s / 10 evals], avg: 2.72 (s/batch)\n  ==> Testing Float32 with torch backend, on GPU, forward\n  Elapsed time: 8.083082 [s / 10 evals], avg: 0.81 (s/batch)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}